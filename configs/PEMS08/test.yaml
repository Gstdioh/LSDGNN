---
base_dir: data/model
log_level: INFO  # logger 的级别
mode: test  # ['train', 'test']
data:
  # 数据
  data_file: datasets/PEMS08/PEMS08_6_2_2.npz  # 数据文件
  forcast_type: flow  # ['flow', 'speed'] 预测流量或者速度
  graph_pkl_filename: datasets/PEMS08/adj_mx.pkl  # 邻接矩阵文件
  adj_type: doubletransition  # adj type to preprocessing

  # batch
  batch_size: 32
  val_batch_size: 32
  test_batch_size: 32

  # 用于创建数据集
  time_interval: 5  # 时间间隔，默认 5min
  history_length: 12  # 历史序列的长度
  prediction_length: 12  # 预测序列的长度

model_args:
  num_feat:       1
  hidden_dim:     32
  skip_channels:  64
  end_channels:   128

  input_seq_len:  12
  output_seq_len: 12

  node_dim:       40
  time_day_dim:   16
  time_week_dim:  7

  num_nodes:      170
  num_layers:     3

  # ModelLayer
  dropout:          0.3  # from MTGNN
  short_kernel_set: [1, 2, 3]
  long_kernel_set:  [1, 6, 7]
  ks:               2
  reset_beta:       0.05
  lamda:            0.5

  # GraphConstructor
  # 选择构造哪些矩阵
  use_pre:    true
  pre_graph:  []
  use_ada:    true
  use_dy:     true
  # 自适应矩阵
  tanh_alpha: 3
  top_k:      20  # 用于稀疏化
  # 动态矩阵
  dy_graph_dropout: 0.1  # from D2STGNN

train:
  device: cuda  # ["cuda", "cpu"]

  # 课程学习
  step_size: 2500
  cl: false

  # 模型载入和保存参数
  has_saved_state: false  # 是否有权重文件
  model_state_pth: null  # 模型权重文件，包含模型参数和训练状态 ['model_state_dict', 'epoch', 'optimizer_state_dict']
  save_model: true  # 是否保存模型参数和训练状态

  # 学习率相关参数
  base_lr: 0.001  # 初始学习率
  lr_decay_ratio: 0.1  # 学习率的递减率
  steps: [30, 40]  # MultiStepLR 每一个元素代表何时调整学习率
  min_learning_rate: 2.0e-06
  weight_decay: 0.0001  # Weight Decay是一个正则化技术，作用是抑制模型的过拟合，以此来提高模型的泛化性

  # 日志显示参数
  log_every: 1  # 每经过log_every（默认1）个epoch，显示一次训练和验证的结果
  test_every_n_epochs: 1  # 每经过test_every_n_epochs（默认10）个epoch，显示一次测试的结果

  epochs: 100  # 训练总epoch数
  patience: 50  # 若经过50epoch，loss还没有降低，则退出训练
  save_epoch: 10  # 每训练 save_epoch，则保存一次模型

  epsilon: 1.0e-3  # 表示一个小常数,用于防止除数为0
  global_step: 0
  max_grad_norm: 5  # 最大允许梯度，用于梯度裁剪
  max_to_keep: 100
  optimizer: adam
  dropout: 0